
------------------------------------------
* There's a bug where the rdoc generates Crauigscrape weird in the package. It has to do with this not being the case in the gem:
	  * # NOTE: If you don't put libcraigscrape.rb at the beginning, the rdoc ends up looking a little screwy
      rdoc.rdoc_files.add RDOC_FILES+Dir.glob('lib/*.rb').sort_by{|a,b| (a == 'lib/libcraigscrape.rb') ? -1 : 0 } 
		* In fact, we might want to move all those requires up to the top of libcraigscrape again  once we fix this... 

* Add craigwatch filter object tests....

------------------------------------------
Possible features?:
 * FEATURE: Rather then 'search/sss?query=artist+needed', maybe use CraigScrape::search_for('artist needed')
 * FEATURE: Support for post submissions?
 * FEATURE: Add the craigwatch_debug feature - and monitor it... (There's a TODO in there...)
	* Shows the current progress...? (pages fetched, objects in caches..) 
 * FEATURE: Get the YAML template features working in the chris_report.yml
 	* should be pretty easy - I think we just add to the schema
 	* Might have to do this yourself with a search_templates section and an search ':include' thing
   * Should we have 'defined searches' in the yaml and then apply these defitions to a report? 
 		* It would be nice to have one search definition for 'art I want' and then allow these
	 	* to be referenced in separate reports for 'art in florida', 'art in nyc', 'art everywhere esle' ..
	 	* The other  thing I'd like to do though is have "New art watch/Classic Artwatch" type reports that look
	 	* separate - but that dont cause the crawl to happen twice. Just once with two reports per crawl..
 * FEATURE: Page-caching? Maybe? Any interest? might be nice for geocaching...
 * FEATURE: Stats in the email: bytes transferred, generation time, urls scrapped, posts scrapped
 
 * FEATURE: We might want to parse the sub-locations in the geo-location code... (so for miami: brw/mia/wpb)

------------------------------------------
# Quickie craigscrape examples/tests:
$: << './lib'
require 'libcraigscrape'

CraigScrape.new('us/fl/miami', 'us/fl/keys').posts_since(Time.now - 3600*48, 'search/sss?query=z06')
CraigScrape.new('us/fl/miami').posts('search/sss?query=z06')
i=0; CraigScrape.new('us/fl/miami', 'us/fl/keys').each_post('rea', 'search/sss?query=rack'){|p| break if i>50; puts p.inspect ;i += 1;}
CraigScrape.new('us/fl/miami', 'us/fl/keys').each_listing('rea', 'search/sss?query=rack'){ |listing| puts listing.inspect }
CraigScrape.new('us/fl/miami', 'us/fl/keys').listings('rea', 'search/sss?query=rack')


-----------------------------------------
# Quickie way to analyze an email:
$: << './lib'
require 'libcraigscrape'

email=<<EOD
email contents here
EOD
r=/regex-here/

email.tr('\n', '').scan( /http\:\/\/[^ \"]+/).reject{|l| !/\.html/.match l}.each{ |l|
  puts "\nURL: %s" % l
  c = CraigScrape::Posting.new l
  puts "  * Label : %s" % r.match(c.label).to_a[0]
  puts "  * Contents: %s" % r.match(c.contents_as_plain).to_a[0]
}

-----------------------------------------
